Metadata-Version: 2.1
Name: reppy2
Version: 0.3.6
Summary: Replacement robots.txt Parser in pure Python
Home-page: http://github.com/seomoz/reppy
Author: Dan Lecocq
Author-email: dan@moz.com
License: MIT License
Keywords: utilities
Platform: UNKNOWN
Classifier: License :: OSI Approved :: MIT License
Classifier: Development Status :: 3 - Alpha
Classifier: Environment :: Web Environment
Classifier: Intended Audience :: Developers
Classifier: Topic :: Internet :: WWW/HTTP
License-File: LICENSE
Requires-Dist: python-dateutil
Requires-Dist: requests
Provides-Extra: docs
Requires-Dist: Sphinx (>=3.3.1) ; extra == 'docs'
Requires-Dist: sphinx-rtd-theme (>=0.5.0) ; extra == 'docs'
Requires-Dist: doc8 (>=0.8.1) ; extra == 'docs'
Provides-Extra: testing
Requires-Dist: pytest (>=6) ; extra == 'testing'
Requires-Dist: pytest-xdist (>=2) ; extra == 'testing'
Requires-Dist: mock ; extra == 'testing'

Replaces the built-in robotsparser with a
RFC-conformant implementation that supports modern robots.txt constructs like
Sitemaps, Allow, and Crawl-delay. Main features:

- Memoization of fetched robots.txt
- Expiration taken from the `Expires` header
- Batch queries
- Configurable user agent for fetching robots.txt
- Automatic refetching basing on expiration

This is a patched fork of the last pure Python version that
works on Python 2 and 3.

