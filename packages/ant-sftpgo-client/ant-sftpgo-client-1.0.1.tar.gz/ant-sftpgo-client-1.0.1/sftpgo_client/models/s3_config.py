# coding: utf-8

"""
    SFTPGo

    SFTPGo REST API  # noqa: E501

    OpenAPI spec version: 2.4.4
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

import pprint
import re  # noqa: F401

import six

class S3Config(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """
    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'bucket': 'str',
        'region': 'str',
        'access_key': 'str',
        'access_secret': 'Secret',
        'endpoint': 'str',
        'storage_class': 'str',
        'upload_part_size': 'int',
        'upload_concurrency': 'int',
        'key_prefix': 'str'
    }

    attribute_map = {
        'bucket': 'bucket',
        'region': 'region',
        'access_key': 'access_key',
        'access_secret': 'access_secret',
        'endpoint': 'endpoint',
        'storage_class': 'storage_class',
        'upload_part_size': 'upload_part_size',
        'upload_concurrency': 'upload_concurrency',
        'key_prefix': 'key_prefix'
    }

    def __init__(self, bucket=None, region=None, access_key=None, access_secret=None, endpoint=None, storage_class=None, upload_part_size=None, upload_concurrency=None, key_prefix=None):  # noqa: E501
        """S3Config - a model defined in Swagger"""  # noqa: E501
        self._bucket = None
        self._region = None
        self._access_key = None
        self._access_secret = None
        self._endpoint = None
        self._storage_class = None
        self._upload_part_size = None
        self._upload_concurrency = None
        self._key_prefix = None
        self.discriminator = None
        if bucket is not None:
            self.bucket = bucket
        if region is not None:
            self.region = region
        if access_key is not None:
            self.access_key = access_key
        if access_secret is not None:
            self.access_secret = access_secret
        if endpoint is not None:
            self.endpoint = endpoint
        if storage_class is not None:
            self.storage_class = storage_class
        if upload_part_size is not None:
            self.upload_part_size = upload_part_size
        if upload_concurrency is not None:
            self.upload_concurrency = upload_concurrency
        if key_prefix is not None:
            self.key_prefix = key_prefix

    @property
    def bucket(self):
        """Gets the bucket of this S3Config.  # noqa: E501


        :return: The bucket of this S3Config.  # noqa: E501
        :rtype: str
        """
        return self._bucket

    @bucket.setter
    def bucket(self, bucket):
        """Sets the bucket of this S3Config.


        :param bucket: The bucket of this S3Config.  # noqa: E501
        :type: str
        """

        self._bucket = bucket

    @property
    def region(self):
        """Gets the region of this S3Config.  # noqa: E501


        :return: The region of this S3Config.  # noqa: E501
        :rtype: str
        """
        return self._region

    @region.setter
    def region(self, region):
        """Sets the region of this S3Config.


        :param region: The region of this S3Config.  # noqa: E501
        :type: str
        """

        self._region = region

    @property
    def access_key(self):
        """Gets the access_key of this S3Config.  # noqa: E501


        :return: The access_key of this S3Config.  # noqa: E501
        :rtype: str
        """
        return self._access_key

    @access_key.setter
    def access_key(self, access_key):
        """Sets the access_key of this S3Config.


        :param access_key: The access_key of this S3Config.  # noqa: E501
        :type: str
        """

        self._access_key = access_key

    @property
    def access_secret(self):
        """Gets the access_secret of this S3Config.  # noqa: E501


        :return: The access_secret of this S3Config.  # noqa: E501
        :rtype: Secret
        """
        return self._access_secret

    @access_secret.setter
    def access_secret(self, access_secret):
        """Sets the access_secret of this S3Config.


        :param access_secret: The access_secret of this S3Config.  # noqa: E501
        :type: Secret
        """

        self._access_secret = access_secret

    @property
    def endpoint(self):
        """Gets the endpoint of this S3Config.  # noqa: E501

        optional endpoint  # noqa: E501

        :return: The endpoint of this S3Config.  # noqa: E501
        :rtype: str
        """
        return self._endpoint

    @endpoint.setter
    def endpoint(self, endpoint):
        """Sets the endpoint of this S3Config.

        optional endpoint  # noqa: E501

        :param endpoint: The endpoint of this S3Config.  # noqa: E501
        :type: str
        """

        self._endpoint = endpoint

    @property
    def storage_class(self):
        """Gets the storage_class of this S3Config.  # noqa: E501


        :return: The storage_class of this S3Config.  # noqa: E501
        :rtype: str
        """
        return self._storage_class

    @storage_class.setter
    def storage_class(self, storage_class):
        """Sets the storage_class of this S3Config.


        :param storage_class: The storage_class of this S3Config.  # noqa: E501
        :type: str
        """

        self._storage_class = storage_class

    @property
    def upload_part_size(self):
        """Gets the upload_part_size of this S3Config.  # noqa: E501

        the buffer size (in MB) to use for multipart uploads. The minimum allowed part size is 5MB, and if this value is set to zero, the default value (5MB) for the AWS SDK will be used. The minimum allowed value is 5.  # noqa: E501

        :return: The upload_part_size of this S3Config.  # noqa: E501
        :rtype: int
        """
        return self._upload_part_size

    @upload_part_size.setter
    def upload_part_size(self, upload_part_size):
        """Sets the upload_part_size of this S3Config.

        the buffer size (in MB) to use for multipart uploads. The minimum allowed part size is 5MB, and if this value is set to zero, the default value (5MB) for the AWS SDK will be used. The minimum allowed value is 5.  # noqa: E501

        :param upload_part_size: The upload_part_size of this S3Config.  # noqa: E501
        :type: int
        """

        self._upload_part_size = upload_part_size

    @property
    def upload_concurrency(self):
        """Gets the upload_concurrency of this S3Config.  # noqa: E501

        the number of parts to upload in parallel. If this value is set to zero, the default value (2) will be used  # noqa: E501

        :return: The upload_concurrency of this S3Config.  # noqa: E501
        :rtype: int
        """
        return self._upload_concurrency

    @upload_concurrency.setter
    def upload_concurrency(self, upload_concurrency):
        """Sets the upload_concurrency of this S3Config.

        the number of parts to upload in parallel. If this value is set to zero, the default value (2) will be used  # noqa: E501

        :param upload_concurrency: The upload_concurrency of this S3Config.  # noqa: E501
        :type: int
        """

        self._upload_concurrency = upload_concurrency

    @property
    def key_prefix(self):
        """Gets the key_prefix of this S3Config.  # noqa: E501

        key_prefix is similar to a chroot directory for a local filesystem. If specified the user will only see contents that starts with this prefix and so you can restrict access to a specific virtual folder. The prefix, if not empty, must not start with \"/\" and must end with \"/\". If empty the whole bucket contents will be available  # noqa: E501

        :return: The key_prefix of this S3Config.  # noqa: E501
        :rtype: str
        """
        return self._key_prefix

    @key_prefix.setter
    def key_prefix(self, key_prefix):
        """Sets the key_prefix of this S3Config.

        key_prefix is similar to a chroot directory for a local filesystem. If specified the user will only see contents that starts with this prefix and so you can restrict access to a specific virtual folder. The prefix, if not empty, must not start with \"/\" and must end with \"/\". If empty the whole bucket contents will be available  # noqa: E501

        :param key_prefix: The key_prefix of this S3Config.  # noqa: E501
        :type: str
        """

        self._key_prefix = key_prefix

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value
        if issubclass(S3Config, dict):
            for key, value in self.items():
                result[key] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, S3Config):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
