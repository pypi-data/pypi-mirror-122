class Tokenizer:
    """Tokenizer implementation"""

    def word_tokenizer(self, text):
        """Split the text into words"""
        ...

    def sentence_tokenizer(self, text):
        """Split the text into sentences"""
        ...
